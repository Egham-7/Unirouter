{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Model Routing Experiment\n",
    "\n",
    "**Paper**: [Universal Model Routing for Efficient LLM Inference](https://arxiv.org/pdf/2502.08773)  \n",
    "**Authors**: Jitkrittum et al. (2025)\n",
    "\n",
    "## Core Concept\n",
    "Route queries to different LLMs using **cluster-based error profiles** that work with new unseen models without retraining.\n",
    "\n",
    "**Key Innovation**: Î¨(m) vectors - error rates per question cluster for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup\n",
    "!pip install -q openai scikit-learn numpy sentence-transformers datasets pandas pydantic matplotlib groq\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pydantic import BaseModel\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"âœ… Setup complete\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Add your API keys as environment variables:\\n# export OPENAI_API_KEY='your-key'\\n# export GROQ_API_KEY='your-key'\\n\\nAPI_KEYS = {\\n    'openai': os.getenv('OPENAI_API_KEY'),\\n    'groq': os.getenv('GROQ_API_KEY')\\n}\\n\\n# Model pool with cost estimates\\nMODELS = [\\n    {'name': 'gpt-4o', 'provider': 'openai', 'cost': 6.25},\\n    {'name': 'gpt-4.1', 'provider': 'openai', 'cost': 5.00},\\n    {'name': 'gpt-4o-mini', 'provider': 'openai', 'cost': 0.375},\\n    {'name': 'meta-llama/llama-guard-4-12b', 'provider': 'groq', 'cost': 0.20},\\n    {'name': 'llama-3.1-8b-instant', 'provider': 'groq', 'cost': 0.065}\\n]\\n\\nprint(f\\\"âœ… {len(MODELS)} models configured\\\")\\nprint(f\\\"ðŸ“Š Cost range: ${min(m['cost'] for m in MODELS)} - ${max(m['cost'] for m in MODELS)}\\\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add your API keys\n",
    "API_KEYS = {\n",
    "    'openai': 'your-openai-key-here',\n",
    "    'groq': 'your-groq-key-here'\n",
    "}\n",
    "\n",
    "MODELS = [\n",
    "    {'name': 'gpt-4o', 'provider': 'openai', 'cost': 6.25},\n",
    "    {'name': 'gpt-4.1', 'provider': 'openai', 'cost': 5.00},\n",
    "    {'name': 'gpt-4o-mini', 'provider': 'openai', 'cost': 0.375},\n",
    "    {'name': 'meta-llama/llama-guard-4-12b', 'provider': 'groq', 'cost': 0.20},\n",
    "    {'name': 'llama-3.1-8b-instant', 'provider': 'groq', 'cost': 0.065}\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(MODELS)} models\")\n",
    "print(f\"ðŸ“Š Cost: ${min(m['cost'] for m in MODELS)} - ${max(m['cost'] for m in MODELS)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set + Clustering\n",
    "\n",
    "**Paper Method**: MMLU validation set, K-means clustering on question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load MMLU validation\n",
    "dataset = load_dataset(\"cais/mmlu\", \"all\", split=\"validation\")\n",
    "dataset = dataset.shuffle(seed=42).select(range(200))\n",
    "\n",
    "# Format for MCQ\n",
    "VALIDATION_SET = []\n",
    "for i, item in enumerate(dataset):\n",
    "    prompt = f\"{item['question']}\\nA) {item['choices'][0]}\\nB) {item['choices'][1]}\\nC) {item['choices'][2]}\\nD) {item['choices'][3]}\\nAnswer:\"\n",
    "    VALIDATION_SET.append({\n",
    "        'prompt': prompt,\n",
    "        'answer': ['A', 'B', 'C', 'D'][item['answer']],\n",
    "        'question': item['question']\n",
    "    })\n",
    "\n",
    "print(f\"âœ… {len(VALIDATION_SET)} validation examples\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cluster questions\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedder.encode([item['question'] for item in VALIDATION_SET])\n",
    "\n",
    "K = 10\n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Group by cluster\n",
    "validation_clusters = defaultdict(list)\n",
    "for i, cluster_id in enumerate(clusters):\n",
    "    validation_clusters[cluster_id].append(VALIDATION_SET[i])\n",
    "\n",
    "print(f\"âœ… {K} clusters created\")\n",
    "for k in range(K):\n",
    "    print(f\"  Cluster {k}: {len(validation_clusters[k])} examples\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}