{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Model Routing Experiment\n",
    "\n",
    "**Paper**: [Universal Model Routing for Efficient LLM Inference](https://arxiv.org/pdf/2502.08773)  \n",
    "**Authors**: Jitkrittum et al. (2025)\n",
    "\n",
    "## Core Concept\n",
    "Route queries to different LLMs using **cluster-based error profiles** that work with new unseen models without retraining.\n",
    "\n",
    "**Key Innovation**: Î¨(m) vectors - error rates per question cluster for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "!pip install -q openai scikit-learn numpy sentence-transformers datasets pandas pydantic matplotlib groq\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pydantic import BaseModel\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 5 models\n",
      "ðŸ“Š Cost: $0.065 - $6.25\n"
     ]
    }
   ],
   "source": [
    "# Add your API keys\n",
    "API_KEYS = {\n",
    "    'openai': 'your-openai-key-here',\n",
    "    'groq': 'your-groq-key-here'\n",
    "}\n",
    "\n",
    "MODELS = [\n",
    "    {'name': 'gpt-4o', 'provider': 'openai', 'cost': 6.25},\n",
    "    {'name': 'gpt-4.1', 'provider': 'openai', 'cost': 5.00},\n",
    "    {'name': 'gpt-4o-mini', 'provider': 'openai', 'cost': 0.375},\n",
    "    {'name': 'meta-llama/llama-guard-4-12b', 'provider': 'groq', 'cost': 0.20},\n",
    "    {'name': 'llama-3.1-8b-instant', 'provider': 'groq', 'cost': 0.065}\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(MODELS)} models\")\n",
    "print(f\"ðŸ“Š Cost: ${min(m['cost'] for m in MODELS)} - ${max(m['cost'] for m in MODELS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set + Clustering\n",
    "\n",
    "**Paper Method**: MMLU validation set, K-means clustering on question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 200 validation examples\n"
     ]
    }
   ],
   "source": [
    "# Load MMLU validation\n",
    "dataset = load_dataset(\"cais/mmlu\", \"all\", split=\"validation\")\n",
    "dataset = dataset.shuffle(seed=42).select(range(200))\n",
    "\n",
    "# Format for MCQ\n",
    "VALIDATION_SET = []\n",
    "for i, item in enumerate(dataset):\n",
    "    prompt = f\"{item['question']}\\nA) {item['choices'][0]}\\nB) {item['choices'][1]}\\nC) {item['choices'][2]}\\nD) {item['choices'][3]}\\nAnswer:\"\n",
    "    VALIDATION_SET.append({\n",
    "        'prompt': prompt,\n",
    "        'answer': ['A', 'B', 'C', 'D'][item['answer']],\n",
    "        'question': item['question']\n",
    "    })\n",
    "\n",
    "print(f\"âœ… {len(VALIDATION_SET)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 10 clusters created\n",
      "  Cluster 0: 25 examples\n",
      "  Cluster 1: 23 examples\n",
      "  Cluster 2: 11 examples\n",
      "  Cluster 3: 25 examples\n",
      "  Cluster 4: 26 examples\n",
      "  Cluster 5: 8 examples\n",
      "  Cluster 6: 20 examples\n",
      "  Cluster 7: 25 examples\n",
      "  Cluster 8: 13 examples\n",
      "  Cluster 9: 24 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/anaconda3/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cluster questions\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedder.encode([item['question'] for item in VALIDATION_SET])\n",
    "\n",
    "K = 10\n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Group by cluster\n",
    "validation_clusters = defaultdict(list)\n",
    "for i, cluster_id in enumerate(clusters):\n",
    "    validation_clusters[cluster_id].append(VALIDATION_SET[i])\n",
    "\n",
    "print(f\"âœ… {K} clusters created\")\n",
    "for k in range(K):\n",
    "    print(f\"  Cluster {k}: {len(validation_clusters[k])} examples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
