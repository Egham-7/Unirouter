{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Characterization & Routing\n",
    "\n",
    "**Paper's Core Algorithm**: Compute Î¨(m) error profiles and route based on cost-quality tradeoff.\n",
    "\n",
    "**Routing Rule**: Select model with lowest `error_rate + Î» Ã— cost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run previous notebook first\n",
    "%run 01_unirouter_experiment.ipynb"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def call_llm(model_name: str, provider: str, prompt: str) -> str:\\n    \\\"\\\"\\\"Call LLM and extract A/B/C/D answer\\\"\\\"\\\"\\n    try:\\n        if provider == 'openai':\\n            from openai import OpenAI\\n            client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\\n            \\n            if 'gpt-4' in model_name:\\n                response = client.beta.chat.completions.parse(\\n                    model=model_name,\\n                    messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}],\\n                    response_format=MCQAnswer,\\n                    temperature=0\\n                )\\n                return response.choices[0].message.parsed.answer\\n                \\n        elif provider == 'groq':\\n            from groq import Groq\\n            client = Groq(api_key=os.getenv('GROQ_API_KEY'))\\n            \\n            response = client.chat.completions.create(\\n                model=model_name,\\n                messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt + \\\" Answer with only A, B, C, or D.\\\"}],\\n                temperature=0,\\n                max_tokens=5\\n            )\\n            \\n            answer = response.choices[0].message.content.strip().upper()\\n            for letter in [\\\"A\\\", \\\"B\\\", \\\"C\\\", \\\"D\\\"]:\\n                if letter in answer:\\n                    return letter\\n                    \\n    except Exception as e:\\n        print(f\\\"Error with {model_name}: {e}\\\")\\n        \\n    return \\\"E\\\"  # Error"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MCQAnswer(BaseModel):\n",
    "    answer: Literal[\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "def call_llm(model_name: str, provider: str, prompt: str) -> str:\n",
    "    \"\"\"Call LLM and extract A/B/C/D answer\"\"\"\n",
    "    try:\n",
    "        if provider == 'openai':\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI(api_key=API_KEYS['openai'])\n",
    "            \n",
    "            if 'gpt-4' in model_name:\n",
    "                response = client.beta.chat.completions.parse(\n",
    "                    model=model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    response_format=MCQAnswer,\n",
    "                    temperature=0\n",
    "                )\n",
    "                return response.choices[0].message.parsed.answer\n",
    "                \n",
    "        elif provider == 'groq':\n",
    "            from groq import Groq\n",
    "            client = Groq(api_key=API_KEYS['groq'])\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt + \" Answer with only A, B, C, or D.\"}],\n",
    "                temperature=0,\n",
    "                max_tokens=5\n",
    "            )\n",
    "            \n",
    "            answer = response.choices[0].message.content.strip().upper()\n",
    "            for letter in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "                if letter in answer:\n",
    "                    return letter\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        \n",
    "    return \"E\"  # Error"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Characterization\n",
    "\n",
    "**Formula**: Î¨(m)[k] = error rate of model m on cluster k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def characterize_model(model_name: str, provider: str) -> np.ndarray:\n",
    "    \"\"\"Compute Î¨(m) error profile\"\"\"\n",
    "    print(f\"Characterizing {model_name}...\")\n",
    "    \n",
    "    psi_vector = np.zeros(K)\n",
    "    \n",
    "    for cluster_id in range(K):\n",
    "        cluster_data = validation_clusters[cluster_id]\n",
    "        errors = 0\n",
    "        \n",
    "        for example in cluster_data:\n",
    "            response = call_llm(model_name, provider, example['prompt'])\n",
    "            if response != example['answer']:\n",
    "                errors += 1\n",
    "                \n",
    "        psi_vector[cluster_id] = errors / len(cluster_data)\n",
    "        print(f\"  Cluster {cluster_id}: {psi_vector[cluster_id]:.1%}\")\n",
    "    \n",
    "    return psi_vector\n",
    "\n",
    "# Characterize all models (or load existing)\n",
    "MODEL_DB = {}\n",
    "for model in MODELS:\n",
    "    psi = characterize_model(model['name'], model['provider'])\n",
    "    MODEL_DB[model['name']] = {\n",
    "        'psi_vector': psi,\n",
    "        'provider': model['provider'],\n",
    "        'cost': model['cost']\n",
    "    }\n",
    "\n",
    "print(f\"\\nâœ… {len(MODEL_DB)} models characterized\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Router\n",
    "\n",
    "**Key**: Works with any new model by computing its Î¨(m) profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class UniRouter:\n",
    "    def __init__(self, model_db, kmeans_model, embedder):\n",
    "        self.model_db = model_db\n",
    "        self.kmeans = kmeans_model\n",
    "        self.embedder = embedder\n",
    "        self._normalize_costs()\n",
    "        \n",
    "    def _normalize_costs(self):\n",
    "        costs = [info['cost'] for info in self.model_db.values()]\n",
    "        self.min_cost, self.max_cost = min(costs), max(costs)\n",
    "        \n",
    "        for info in self.model_db.values():\n",
    "            info['norm_cost'] = (info['cost'] - self.min_cost) / (self.max_cost - self.min_cost)\n",
    "    \n",
    "    def route(self, prompt: str, lambda_cost: float = 0.1) -> dict:\n",
    "        \"\"\"Route prompt using paper's algorithm\"\"\"\n",
    "        \n",
    "        # Find cluster\n",
    "        embedding = self.embedder.encode([prompt])[0]\n",
    "        cluster_id = self.kmeans.predict(embedding.reshape(1, -1))[0]\n",
    "        \n",
    "        # Score models: error + Î» Ã— cost\n",
    "        best_model, best_score = None, float('inf')\n",
    "        \n",
    "        for model_name, info in self.model_db.items():\n",
    "            error_rate = info['psi_vector'][cluster_id]\n",
    "            score = error_rate + lambda_cost * info['norm_cost']\n",
    "            \n",
    "            if score < best_score:\n",
    "                best_score, best_model = score, model_name\n",
    "        \n",
    "        return {\n",
    "            'model': best_model,\n",
    "            'cluster': int(cluster_id),\n",
    "            'cost': self.model_db[best_model]['cost']\n",
    "        }\n",
    "\n",
    "router = UniRouter(MODEL_DB, kmeans, embedder)\n",
    "print(\"âœ… Router ready\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing Examples\n",
    "\n",
    "**Î» = 0**: Quality-only  \n",
    "**Î» = 10**: Cost-focused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "test_prompts = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain quantum computing\",\n",
    "    \"Write Python code to sort a list\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nðŸ“ {prompt}\")\n",
    "    for Î» in [0.0, 0.1, 1.0, 10.0]:\n",
    "        result = router.route(prompt, lambda_cost=Î»)\n",
    "        print(f\"  Î»={Î»:4.1f}: {result['model']:<25} (${result['cost']:.3f})\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}